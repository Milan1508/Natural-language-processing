{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to preprocess text using the following techniques:\n",
    "    - Stopwords removal\n",
    "    - Tokenization\n",
    "    - Stemming\n",
    "    - Lemmatization\n",
    "* How to build a spam detector using one of the following models:\n",
    "    - Bag-of-words model\n",
    "    - TF-IDF model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequencies and Stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A text is made of characters, words, sentences and paragraphs. The most basic statistical analysis you can do is to look at the word frequency distribution, i.e., visualising the word frequencies of a given text corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To summarise, Zipf’s law (discovered by the linguist-statistician George Zipf) states that the frequency of a word is inversely proportional to the word’s rank, where rank 1 is given to the most frequent word, rank 2 is given to the second most frequent, and so on. This is also called the <b> power law distribution </b>.\n",
    "\n",
    "\n",
    "According to Zipf’s law, the frequency of a given word is dependent on the inverse of its rank.\n",
    "\n",
    " \n",
    "\n",
    "# f(r, α) ∝ 1/rα\n",
    "\n",
    "### - where\n",
    "* α ≈ 1\n",
    "* r = rank of a word\n",
    "* f(r, α) = frequency in the corpus\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the most frequent term occurs cf1 times, then the second most frequent term has half as many occurrences, the third most frequent term a third as many occurrences, and so on. The intuition is that frequency decreases very rapidly with rank. Equation 3 is one of the simplest ways of formalizing such a rapid decrease and it has been found to be a reasonably good model.\n",
    "\n",
    "## https://nlp.stanford.edu/IR-book/html/htmledition/zipfs-law-modeling-the-distribution-of-terms-1.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zipf’s law helps us form the basic intuition for stopwords; these words have the highest frequencies (or lowest ranks) in a text and are typical of limited importance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadly, there are three kinds of words present in any text corpus:\n",
    "\n",
    "* Highly frequent words called stopwords, such as ‘is’, ‘an’ and ‘the’.\n",
    "* Significant words, which are typically more important to understand the text.\n",
    "* Rarely occurring words, which are again less important than significant words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, stopwords are removed from the text for two reasons:\n",
    "\n",
    "* They provide no useful information, especially in applications such as spam detectors or search engines. Therefore, you’re going to remove stopwords from the spam data set.\n",
    "* As far as the data size is concerned, since the frequency of words is high, removing stopwords will result in smaller data and reduced size results in the faster computation of text data. There’s also the advantage of fewer features if stopwords are removed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are exceptions when these words should not be removed. In the next module, you’ll learn concepts such as POS (parts of speech), tagging and parsing, where stopwords are preserved because they provide meaningful (grammatical) information in those applications. Generally, stopwords are removed unless they prove to be helpful in your application or analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, you won’t remove the rarely occurring words because they might provide useful information for spam detection. Also, removing them provides no added efficiency in computation since their frequency is so low."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make frequency distribution from a text corpus and remove stopwords in Python using the NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milan\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gutenberg.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from nltk import FreqDist\n",
    "\n",
    "# load the ebook\n",
    "url = \"https://www.gutenberg.org/files/16/16-0.txt\"\n",
    "peter_pan = requests.get(url,verify = False).text\n",
    "\n",
    "# break the book into different words using the split() method\n",
    "peter_pan_words = peter_pan.split()# write your code here\n",
    "\n",
    "# build frequency distribution using NLTK's FreqDist() function\n",
    "word_frequency =  FreqDist(peter_pan_words)# write your code here\n",
    "\n",
    "# extract the frequency of third most frequent word\n",
    "freq = word_frequency.most_common(3)[2][1]\n",
    "\n",
    "# print the third most frequent word - don't change the following code, it is used to evaluate the code\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from nltk import FreqDist\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # load the ebook\n",
    "# url = \"https://www.gutenberg.org/files/16/16-0.txt\"\n",
    "# peter_pan = requests.get(url, verify = False).text\n",
    "\n",
    "# # break the book into different words using the split() method\n",
    "# peter_pan_words = peter_pan.split()\n",
    "\n",
    "# # extract nltk stop word list\n",
    "# stopwords = stopwords.words('english')\n",
    "\n",
    "# # remove 'stopwords' from 'peter_pan_words'\n",
    "# no_stops = [word for word in peter_pan_words if word not in stopwords]\n",
    "\n",
    "# # create word frequency of no_stops\n",
    "# word_frequency = FreqDist(no_stops)\n",
    "\n",
    "# # extract the most frequent word and its frequency\n",
    "# frequency = word_frequency.most_common(1)[0][1]\n",
    "\n",
    "# # print the third most frequent word - don't change the following code, it is used to evaluate the code\n",
    "# print(frequency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now doing tockenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"At nine o'clock I visited him myself. It looks like religious mania, and he'll soon think that he himself is God.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "represent text in a format that you can feed into machine learning algorithms. The most common and popular approach is creating a bag-of-words representation of your text data. The central idea is that any given piece of text, i.e., tweets, articles, messages, emails, etc., can be ‘represented’ by a list of all the words that occur in it (after removing the stopwords), where the sequence of occurrence does not matter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can create ‘bags’ for representing each of the messages in your training and test data set. But how do you go from these bags to building a spam classifier?\n",
    "\n",
    "\n",
    "Let’s say for most of the spam messages, the bags contain words such as prize and lottery, and most of the ham bags do not. Now, when you run into a new message, look at its ‘bag-of-words’ representation. Does the bag for this message resemble that of messages you already know as spam, or does it not resemble them? Based on the answer to the previous question, you can then classify the message.\n",
    "\n",
    " \n",
    "\n",
    "The next question is, how do you get a machine to do all that? Well, it turns out that for doing that, you need to represent all the bags in a matrix format, after which you can use ML algorithms such as Naive Bayes, logistic regression and SVM to do the final classification.\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that’s how the text is represented in the form of a matrix. It can then be used to train machine learning models. Each document sits on a separate row, and each word of the vocabulary has its own column. These vocabulary words are also called <b>features </b> of the text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words representation is also called the bag-of-words model, but this is not to be confused with a machine learning model. A bag-of-words model is just the matrix that you get from text data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to note is that the values inside any cell can be filled in either of the two ways:\n",
    "\n",
    "* Fill the cell with the frequency of a word (i.e., a cell can have a value of 0 or more)\n",
    "* Fill the cell with either 0, in case the word is not present, or 1, in case the word is present (binary format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both approaches work fine and do not usually result in a big difference. The frequency approach is slightly more popular, and the NLTK library in Python also fills the bag-of-words model with word frequencies rather than binary 0 or 1 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = \"there was one place on my ankle that was itching\"\n",
    "string2 = \"but you did not scratch it\"\n",
    "string3 = \"and then my ear began to itch\"\n",
    "string4 = \"and next to my back\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = string1 +\" \" + string2+\" \" + string3 +\" \" + string4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there was one place on my ankle that was itching but you did not scratch it and then my ear began to itch and next to my back'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = main.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ls))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words module last question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    'changes documents to lower case and remove stopwords'\n",
    "\n",
    "    document = document.lower()\n",
    "    words = word_tokenize(document)\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    document = \" \".join(words)\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                               message  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\"SMSSpamCollection.txt\", sep=\"\\t\", names=[\"label\", \"message\"])\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = spam.iloc[0:100,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...\n",
      "1                                                                           Ok lar... Joking wif u oni...\n",
      "2     Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...\n",
      "3                                                       U dun say so early hor... U c already then say...\n",
      "4                                           Nah I don't think he goes to usf, he lives around here though\n",
      "                                                     ...                                                 \n",
      "95    Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify...\n",
      "96                                                                      Watching telugu movie..wat abt u?\n",
      "97                                                    i see. When we finish we have loads of loans to pay\n",
      "98    Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appoint...\n",
      "99                                                                        I see a cup of coffee animation\n",
      "Name: message, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "messages = spam.message\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\", \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\", 'Even my brother is not like to speak with me. They treat me like aids patent.', \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\", 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\", 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', 'URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18', \"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\", 'I HAVE A DATE ON SUNDAY WITH WILL!!', 'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL', \"Oh k...i'm watching here:)\", 'Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.', 'Fine if that\\x92s the way u feel. That\\x92s the way its gota b', 'England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+', 'Is that seriously how you spell his name?', 'I‘m going to try for 2 months ha ha only joking', 'So ü pay first lar... Then when is da stock comin...', 'Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?', 'Ffffffffff. Alright no way I can meet up with you sooner?', \"Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol\", 'Lol your always so convincing.', \"Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?\", \"I'm back &amp; we're packing the car now, I'll let you know if there's room\", 'Ahhh. Work. I vaguely remember that! What does it feel like? Lol', \"Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us\", \"Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You? \", 'K tell me anything about you.', 'For fear of fainting with the of all that housework you just did? Quick have a cuppa', 'Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged', 'Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am', \"Oops, I'll let you know when my roommate's done\", 'I see the letter B on my car', 'Anything lor... U decide...', \"Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything!\", 'Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola', 'Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy', '07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow', 'WHO ARE YOU SEEING?', 'Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches...', 'No calls..messages..missed calls', \"Didn't you get hep b immunisation in nigeria.\", 'Fair enough, anything going on?', \"Yeah hopefully, if tyler can't do it I could maybe ask around a bit\", \"U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers.\", 'What you thinked about me. First time you saw me in class.', 'A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;', \"K fyi x has a ride early tomorrow morning but he's crashing at our place tonight\", 'Wow. I never realized that you were so embarassed by your accomodations. I thought you liked it, since i was doing the best i could and you always seemed so happy about \"the cave\". I\\'m sorry I didn\\'t and don\\'t have more to give. I\\'m sorry i offered. I\\'m sorry your room was so embarassing.', 'SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV', 'Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;', 'Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! ', \"Sorry, I'll call later in meeting.\", 'Tell where you reached', 'Yes..gauti and sehwag out of odi series.', \"Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is killing me.\", 'Ha ha ha good joke. Girls are situation seekers.', 'Its a part of checking IQ', 'Sorry my roommates took forever, it ok if I come by now?', 'Ok lar i double check wif da hair dresser already he said wun cut v short. He said will cut until i look nice.', 'As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a £1500 Bonus Prize, call 09066364589', 'Today is \"song dedicated day..\" Which song will u dedicate for me? Send this to all ur valuable frnds but first rply me...', 'Urgent UR awarded a complimentary trip to EuroDisinc Trav, Aco&Entry41 Or £1000. To claim txt DIS to 87121 18+6*£1.50(moreFrmMob. ShrAcomOrSglSuplt)10, LS1 3AJ', 'Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken\\'s stuff!', 'I plane to give on this month end.', 'Wah lucky man... Then can save money... Hee...', 'Finished class where are you.', 'HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX', 'K..k:)where are you?how did you performed?', 'U can call me now...', 'I am waiting machan. Call me once you free.', 'Thats cool. i am a gentleman and will treat you with dignity and respect.', 'I like you peoples very much:) but am very shy pa.', 'Does not operate after  &lt;#&gt;  or what', \"Its not the same here. Still looking for a job. How much do Ta's earn there.\", \"Sorry, I'll call later\", 'K. Did you call me just now ah? ', 'Ok i am on the way to home hi hi', 'You will be in the place of that man', 'Yup next stop.', \"I call you later, don't have network. If urgnt, sms me.\", \"For real when u getting on yo? I only need 2 more tickets and one more jacket and I'm done. I already used all my multis.\", \"Yes I started to send requests to make it but pain came back so I'm back in bed. Double coins at the factory too. I gotta cash in all my nitros.\", \"I'm really not up to it still tonight babe\", 'Ela kano.,il download, come wen ur free..', 'Yeah do! Don‘t stand to close tho- you‘ll catch something!', \"Sorry to be a pain. Is it ok if we meet another night? I spent late afternoon in casualty and that means i haven't done any of y stuff42moro and that includes all my time sheets and that. Sorry. \", 'Smile in Pleasure Smile in Pain Smile when trouble pours like Rain Smile when sum1 Hurts U Smile becoz SOMEONE still Loves to see u Smiling!!', 'Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed £1000 cash or £5000 prize!', 'Havent planning to buy later. I check already lido only got 530 show in e afternoon. U finish work already?', 'Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16', 'Watching telugu movie..wat abt u?', 'i see. When we finish we have loads of loans to pay', 'Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appointment at four so need to get home n shower beforehand. Does that cause prob for u?\"', 'I see a cup of coffee animation']\n"
     ]
    }
   ],
   "source": [
    "messages = [message for message in messages]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go jurong point , crazy .. available bugis n great world la e buffet ... cine got amore wat ...', 'ok lar ... joking wif u oni ...', \"free entry 2 wkly comp win fa cup final tkts 21st may 2005. text fa 87121 receive entry question ( std txt rate ) & c 's apply 08452810075over18 's\", 'u dun say early hor ... u c already say ...', \"nah n't think goes usf , lives around though\", \"freemsg hey darling 's 3 week 's word back ! 'd like fun still ? tb ok ! xxx std chgs send , £1.50 rcv\", 'even brother like speak . treat like aids patent .', \"per request 'melle melle ( oru minnaminunginte nurungu vettam ) ' set callertune callers . press * 9 copy friends callertune\", 'winner ! ! valued network customer selected receivea £900 prize reward ! claim call 09061701461. claim code kl341 . valid 12 hours .', 'mobile 11 months ? u r entitled update latest colour mobiles camera free ! call mobile update co free 08002986030', \"'m gon na home soon n't want talk stuff anymore tonight , k ? 've cried enough today .\", 'six chances win cash ! 100 20,000 pounds txt > csh11 send 87575. cost 150p/day , 6days , 16+ tsandcs apply reply hl 4 info', 'urgent ! 1 week free membership £100,000 prize jackpot ! txt word : claim : 81010 & c www.dbuk.net lccltd pobox 4403ldnw1a7rw18', \"'ve searching right words thank breather . promise wont take help granted fulfil promise . wonderful blessing times .\", 'date sunday ! !', 'xxxmobilemovieclub : use credit , click wap link next txt message click > > http : //wap . xxxmobilemovieclub.com ? n=qjkgighjjgcbl', \"oh k ... 'm watching : )\", 'eh u remember 2 spell name ... yes . v naughty make v wet .', 'fine that\\x92s way u feel . that\\x92s way gota b', 'england v macedonia - dont miss goals/team news . txt ur national team 87077 eg england 87077 try : wales , scotland 4txt/ú1.20 poboxox36504w45wq 16+', 'seriously spell name ?', '‘ going try 2 months ha ha joking', 'ü pay first lar ... da stock comin ...', 'aft finish lunch go str lor . ard 3 smth lor . u finish ur lunch already ?', 'ffffffffff . alright way meet sooner ?', \"forced eat slice . 'm really hungry tho . sucks . mark getting worried . knows 'm sick turn pizza . lol\", 'lol always convincing .', \"catch bus ? frying egg ? make tea ? eating mom 's left dinner ? feel love ?\", \"'m back & amp ; 're packing car , 'll let know 's room\", 'ahhh . work . vaguely remember ! feel like ? lol', \"wait 's still clear , sure sarcastic 's x n't want live us\", \"yeah got 2 v apologetic . n fallen actin like spoilt child got caught . till 2 ! wo n't go ! badly cheers . ?\", 'k tell anything .', 'fear fainting housework ? quick cuppa', 'thanks subscription ringtone uk mobile charged £5/month please confirm replying yes . reply charged', 'yup ... ok go home look timings msg ü ... xuhui going learn 2nd may lesson 8am', \"oops , 'll let know roommate 's done\", 'see letter b car', 'anything lor ... u decide ...', \"hello ! 's saturday go ? texting see 'd decided anything tomo . 'm trying invite anything !\", 'pls go ahead watts . wanted sure . great weekend . abiola', 'forget tell ? want , need , crave ... ... love sweet arabian steed ... mmmmmm ... yummy', '07732584351 - rodger burns - msg = tried call reply sms free nokia mobile + free camcorder . please call 08000930705 delivery tomorrow', 'seeing ?', 'great ! hope like man well endowed . & lt ; # & gt ; inches ...', 'calls .. messages .. missed calls', \"n't get hep b immunisation nigeria .\", 'fair enough , anything going ?', \"yeah hopefully , tyler ca n't could maybe ask around bit\", \"u n't know stubborn . n't even want go hospital . kept telling mark 'm weak sucker . hospitals weak suckers .\", 'thinked . first time saw class .', 'gram usually runs like & lt ; # & gt ; , half eighth smarter though gets almost whole second gram & lt ; # & gt ;', \"k fyi x ride early tomorrow morning 's crashing place tonight\", \"wow . never realized embarassed accomodations . thought liked , since best could always seemed happy `` cave '' . 'm sorry n't n't give . 'm sorry offered . 'm sorry room embarassing .\", 'sms . ac sptv : new jersey devils detroit red wings play ice hockey . correct incorrect ? end ? reply end sptv', 'know mallika sherawat yesterday ? find @ & lt ; url & gt ;', 'congrats ! 1 year special cinema pass 2 . call 09061209465 ! c suprman v , matrix3 , starwars3 , etc 4 free ! bx420-ip4-5we . 150pm . dont miss !', \"sorry , 'll call later meeting .\", 'tell reached', 'yes .. gauti sehwag odi series .', \"gon na pick $ 1 burger way home . ca n't even move . pain killing .\", 'ha ha ha good joke . girls situation seekers .', 'part checking iq', 'sorry roommates took forever , ok come ?', 'ok lar double check wif da hair dresser already said wun cut v short . said cut look nice .', 'valued customer , pleased advise following recent review mob . awarded £1500 bonus prize , call 09066364589', \"today `` song dedicated day .. '' song u dedicate ? send ur valuable frnds first rply ...\", 'urgent ur awarded complimentary trip eurodisinc trav , aco & entry41 £1000 . claim txt dis 87121 18+6 * £1.50 ( morefrmmob . shracomorsglsuplt ) 10 , ls1 3aj', \"hear new `` divorce barbie '' ? comes ken 's stuff !\", 'plane give month end .', 'wah lucky man ... save money ... hee ...', 'finished class .', 'hi babe im home wan na something ? xx', 'k .. k : ) ? performed ?', 'u call ...', 'waiting machan . call free .', 'thats cool . gentleman treat dignity respect .', 'like peoples much : ) shy pa .', 'operate & lt ; # & gt ;', \". still looking job . much ta 's earn .\", \"sorry , 'll call later\", 'k. call ah ?', 'ok way home hi hi', 'place man', 'yup next stop .', \"call later , n't network . urgnt , sms .\", \"real u getting yo ? need 2 tickets one jacket 'm done . already used multis .\", \"yes started send requests make pain came back 'm back bed . double coins factory . got ta cash nitros .\", \"'m really still tonight babe\", 'ela kano. , il download , come wen ur free ..', 'yeah ! ‘ stand close tho- ‘ catch something !', \"sorry pain . ok meet another night ? spent late afternoon casualty means n't done stuff42moro includes time sheets . sorry .\", 'smile pleasure smile pain smile trouble pours like rain smile sum1 hurts u smile becoz someone still loves see u smiling ! !', 'please call customer service representative 0800 169 6031 10am-9pm guaranteed £1000 cash £5000 prize !', 'havent planning buy later . check already lido got 530 show e afternoon . u finish work already ?', \"free ringtone waiting collected . simply text password `` mix '' 85069 verify . get usher britney . fml , po box 5249 , mk17 92h . 450ppw 16\", 'watching telugu movie .. wat abt u ?', 'see . finish loads loans pay', \"hi . wk ok - hols ! yes bit run . forgot hairdressers appointment four need get home n shower beforehand . cause prob u ? ''\", 'see cup coffee animation']\n"
     ]
    }
   ],
   "source": [
    "messages = [preprocess(message) for message in messages]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(messages)\n",
    "print(bow_model.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 640)\n",
      "['000' '07732584351' '0800' '08000930705' '08002986030'\n",
      " '08452810075over18' '09061209465' '09061701461' '09066364589' '10' '100'\n",
      " '1000' '10am' '11' '12' '1500' '150p' '150pm' '16' '169' '18' '20' '2005'\n",
      " '21st' '2nd' '3aj' '4403ldnw1a7rw18' '450ppw' '4txt' '50' '5000' '5249'\n",
      " '530' '5we' '6031' '6days' '81010' '85069' '87077' '87121' '87575' '8am'\n",
      " '900' '92h' '9pm' 'abiola' 'abt' 'ac' 'accomodations' 'aco' 'actin'\n",
      " 'advise' 'aft' 'afternoon' 'ah' 'ahead' 'ahhh' 'aids' 'almost' 'already'\n",
      " 'alright' 'always' 'amore' 'amp' 'animation' 'another' 'anymore'\n",
      " 'anything' 'apologetic' 'apply' 'appointment' 'arabian' 'ard' 'around'\n",
      " 'ask' 'available' 'awarded' 'babe' 'back' 'badly' 'barbie' 'becoz' 'bed'\n",
      " 'beforehand' 'best' 'bit' 'blessing' 'bonus' 'box' 'breather' 'britney'\n",
      " 'brother' 'buffet' 'bugis' 'burger' 'burns' 'bus' 'buy' 'bx420' 'ca'\n",
      " 'call' 'callers' 'callertune' 'calls' 'camcorder' 'came' 'camera' 'car'\n",
      " 'cash' 'casualty' 'catch' 'caught' 'cause' 'cave' 'chances' 'charged'\n",
      " 'check' 'checking' 'cheers' 'chgs' 'child' 'cine' 'cinema' 'claim'\n",
      " 'class' 'clear' 'click' 'close' 'co' 'code' 'coffee' 'coins' 'collected'\n",
      " 'colour' 'com' 'come' 'comes' 'comin' 'comp' 'complimentary' 'confirm'\n",
      " 'congrats' 'convincing' 'cool' 'copy' 'correct' 'cost' 'could' 'crashing'\n",
      " 'crave' 'crazy' 'credit' 'cried' 'csh11' 'cup' 'cuppa' 'customer' 'cut'\n",
      " 'da' 'darling' 'date' 'day' 'dbuk' 'decide' 'decided' 'dedicate'\n",
      " 'dedicated' 'delivery' 'detroit' 'devils' 'dignity' 'dinner' 'dis'\n",
      " 'divorce' 'done' 'dont' 'double' 'download' 'dresser' 'dun' 'early'\n",
      " 'earn' 'eat' 'eating' 'eg' 'egg' 'eh' 'eighth' 'ela' 'embarassed'\n",
      " 'embarassing' 'end' 'endowed' 'england' 'enough' 'entitled' 'entry'\n",
      " 'entry41' 'etc' 'eurodisinc' 'even' 'fa' 'factory' 'fainting' 'fair'\n",
      " 'fallen' 'fear' 'feel' 'ffffffffff' 'final' 'find' 'fine' 'finish'\n",
      " 'finished' 'first' 'fml' 'following' 'forced' 'forever' 'forget' 'forgot'\n",
      " 'four' 'free' 'freemsg' 'friends' 'frnds' 'frying' 'fulfil' 'fun' 'fyi'\n",
      " 'gauti' 'gentleman' 'get' 'gets' 'getting' 'girls' 'give' 'go' 'goals'\n",
      " 'goes' 'going' 'gon' 'good' 'got' 'gota' 'gram' 'granted' 'great' 'gt'\n",
      " 'guaranteed' 'ha' 'hair' 'hairdressers' 'half' 'happy' 'havent' 'hear'\n",
      " 'hee' 'hello' 'help' 'hep' 'hey' 'hi' 'hl' 'hockey' 'hols' 'home' 'hope'\n",
      " 'hopefully' 'hor' 'hospital' 'hospitals' 'hours' 'housework' 'http'\n",
      " 'hungry' 'hurts' 'ice' 'il' 'im' 'immunisation' 'inches' 'includes'\n",
      " 'incorrect' 'info' 'invite' 'ip4' 'iq' 'jacket' 'jackpot' 'jersey' 'job'\n",
      " 'joke' 'joking' 'jurong' 'kano' 'ken' 'kept' 'killing' 'kl341' 'know'\n",
      " 'knows' 'la' 'lar' 'late' 'later' 'latest' 'lccltd' 'learn' 'left'\n",
      " 'lesson' 'let' 'letter' 'lido' 'like' 'liked' 'link' 'live' 'lives' 'll'\n",
      " 'loads' 'loans' 'lol' 'look' 'looking' 'lor' 'love' 'loves' 'ls1' 'lt'\n",
      " 'lucky' 'lunch' 'macedonia' 'machan' 'make' 'mallika' 'man' 'mark'\n",
      " 'matrix3' 'may' 'maybe' 'means' 'meet' 'meeting' 'melle' 'membership'\n",
      " 'message' 'messages' 'minnaminunginte' 'miss' 'missed' 'mix' 'mk17'\n",
      " 'mmmmmm' 'mob' 'mobile' 'mobiles' 'mom' 'money' 'month' 'months'\n",
      " 'morefrmmob' 'morning' 'move' 'movie' 'msg' 'much' 'multis' 'na' 'nah'\n",
      " 'name' 'national' 'naughty' 'need' 'net' 'network' 'never' 'new' 'news'\n",
      " 'next' 'nice' 'nigeria' 'night' 'nitros' 'nokia' 'nurungu' 'odi'\n",
      " 'offered' 'oh' 'ok' 'one' 'oni' 'oops' 'operate' 'oru' 'pa' 'packing'\n",
      " 'pain' 'part' 'pass' 'password' 'patent' 'pay' 'peoples' 'per'\n",
      " 'performed' 'pick' 'pizza' 'place' 'plane' 'planning' 'play' 'please'\n",
      " 'pleased' 'pleasure' 'pls' 'po' 'pobox' 'poboxox36504w45wq' 'point'\n",
      " 'pounds' 'pours' 'press' 'prize' 'prob' 'promise' 'qjkgighjjgcbl'\n",
      " 'question' 'quick' 'rain' 'rate' 'rcv' 're' 'reached' 'real' 'realized'\n",
      " 'really' 'receive' 'receivea' 'recent' 'red' 'remember' 'reply'\n",
      " 'replying' 'representative' 'request' 'requests' 'respect' 'review'\n",
      " 'reward' 'ride' 'right' 'ringtone' 'rodger' 'room' 'roommate' 'roommates'\n",
      " 'rply' 'run' 'runs' 'said' 'sarcastic' 'saturday' 'save' 'saw' 'say'\n",
      " 'scotland' 'searching' 'second' 'see' 'seeing' 'seekers' 'seemed'\n",
      " 'sehwag' 'selected' 'send' 'series' 'seriously' 'service' 'set' 'sheets'\n",
      " 'sherawat' 'short' 'show' 'shower' 'shracomorsglsuplt' 'shy' 'sick'\n",
      " 'simply' 'since' 'situation' 'six' 'slice' 'smarter' 'smile' 'smiling'\n",
      " 'sms' 'smth' 'someone' 'something' 'song' 'soon' 'sooner' 'sorry' 'speak'\n",
      " 'special' 'spell' 'spent' 'spoilt' 'sptv' 'stand' 'started' 'starwars3'\n",
      " 'std' 'steed' 'still' 'stock' 'stop' 'str' 'stubborn' 'stuff'\n",
      " 'stuff42moro' 'subscription' 'sucker' 'suckers' 'sucks' 'sum1' 'sunday'\n",
      " 'suprman' 'sure' 'sweet' 'ta' 'take' 'talk' 'tb' 'tea' 'team' 'tell'\n",
      " 'telling' 'telugu' 'text' 'texting' 'thank' 'thanks' 'that' 'thats'\n",
      " 'think' 'thinked' 'tho' 'though' 'thought' 'tickets' 'till' 'time'\n",
      " 'times' 'timings' 'tkts' 'today' 'tomo' 'tomorrow' 'tonight' 'took'\n",
      " 'trav' 'treat' 'tried' 'trip' 'trouble' 'try' 'trying' 'tsandcs' 'turn'\n",
      " 'txt' 'tyler' 'uk' 'update' 'ur' 'urgent' 'urgnt' 'url' 'us' 'use' 'used'\n",
      " 'usf' 'usher' 'usually' 'vaguely' 'valid' 'valuable' 'valued' 've'\n",
      " 'verify' 'vettam' 'wah' 'wait' 'waiting' 'wales' 'wan' 'want' 'wanted'\n",
      " 'wap' 'wat' 'watching' 'watts' 'way' 'weak' 'week' 'weekend' 'well' 'wen'\n",
      " 'wet' 'whole' 'wif' 'win' 'wings' 'winner' 'wk' 'wkly' 'wo' 'wonderful'\n",
      " 'wont' 'word' 'words' 'work' 'world' 'worried' 'wow' 'wun' 'www' 'xuhui'\n",
      " 'xx' 'xxx' 'xxxmobilemovieclub' 'yeah' 'year' 'yes' 'yesterday' 'yo'\n",
      " 'yummy' 'yup' 'ú1']\n"
     ]
    }
   ],
   "source": [
    "print(bow_model.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model.toarray().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last segment, you saw the problem of redundant tokens. This will result in an inefficient model when you build your spam detector. Stemming ensures that different variations of a word, say ‘warm’, ‘warmer’, ‘warming’ and ‘warmed’, are represented by a single token, ‘warm’ because they all represent the same information (represented by the ‘stem’ of the word).\n",
    "\n",
    " \n",
    "\n",
    "Another similar preprocessing step (and an alternative to stemming) is lemmatization.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word = 'played'\n",
    "# create function to chop off the suffixes 'ing' and 'ed'\n",
    "def stemmer(word):\n",
    "    if word[-3:] == 'ing':\n",
    "        return word[:-3]# write your code here   \n",
    "    elif word[-2:] == 'ed':\n",
    "         return word[:-2]\n",
    "    return word\n",
    "    \n",
    "print(stemmer(word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
