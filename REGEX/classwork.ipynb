{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\milan\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\milan\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\milan\\anaconda3\\lib\\site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\milan\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\milan\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\milan\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\milan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading : Package '' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"The new registration are potter709@gmail.com, elixir101@gmail.com find any disruptions, kindly contact granger111@gmail.com or severus77@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potter709', 'elixir101', 'granger111', 'severus77']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '(\\S+)@'\n",
    "re.findall(pattern,string)    # non white space meta sequence character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = \"We all know that the fast-food industry is increasing by leaps and bounds these days. People these days are more attracted to junk food because it is appealing. Why is that? People are using manipulative ways to entice people to buy their fast food. Moreover, junk food is prepared very easily. It takes minimum time to prepare it as it does not have any nutritious ingredients. We see how junk food does not have any special ingredients. It just contains common harmful ones in excess like oil, sugar, and more.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'all',\n",
       " 'know',\n",
       " 'that',\n",
       " 'the',\n",
       " 'fast-food',\n",
       " 'industry',\n",
       " 'is',\n",
       " 'increasing',\n",
       " 'by',\n",
       " 'leaps',\n",
       " 'and',\n",
       " 'bounds',\n",
       " 'these',\n",
       " 'days',\n",
       " '.',\n",
       " 'People',\n",
       " 'these',\n",
       " 'days',\n",
       " 'are',\n",
       " 'more',\n",
       " 'attracted',\n",
       " 'to',\n",
       " 'junk',\n",
       " 'food',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'appealing',\n",
       " '.',\n",
       " 'Why',\n",
       " 'is',\n",
       " 'that',\n",
       " '?',\n",
       " 'People',\n",
       " 'are',\n",
       " 'using',\n",
       " 'manipulative',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'entice',\n",
       " 'people',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'their',\n",
       " 'fast',\n",
       " 'food',\n",
       " '.',\n",
       " 'Moreover',\n",
       " ',',\n",
       " 'junk',\n",
       " 'food',\n",
       " 'is',\n",
       " 'prepared',\n",
       " 'very',\n",
       " 'easily',\n",
       " '.',\n",
       " 'It',\n",
       " 'takes',\n",
       " 'minimum',\n",
       " 'time',\n",
       " 'to',\n",
       " 'prepare',\n",
       " 'it',\n",
       " 'as',\n",
       " 'it',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'nutritious',\n",
       " 'ingredients',\n",
       " '.',\n",
       " 'We',\n",
       " 'see',\n",
       " 'how',\n",
       " 'junk',\n",
       " 'food',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'special',\n",
       " 'ingredients',\n",
       " '.',\n",
       " 'It',\n",
       " 'just',\n",
       " 'contains',\n",
       " 'common',\n",
       " 'harmful',\n",
       " 'ones',\n",
       " 'in',\n",
       " 'excess',\n",
       " 'like',\n",
       " 'oil',\n",
       " ',',\n",
       " 'sugar',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize    # nltk.download('punkt || wordnet || )\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "tokenize = word_tokenize(string1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'orange', 'grapefruit']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'[,\\s]+'\n",
    "text = \"apple, banana, orange, grapefruit\"\n",
    "\n",
    "words = re.split(pattern, text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user@example.com', 'info@lpu.in']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\b[A-Za-z0-9.%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "\n",
    "text = 'please contact at user@example.com for more info@lpu.in'\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweet  = 'Great session on #NLP at #Aiconference! Learned a lot about #NLTK :)'\n",
    "tweet = re.sub(r\"http\\S+|RT\\s+|@\\S|#\",\"\", tweet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<re.Match object; span=(0, 6), match='<head>'>\n"
     ]
    }
   ],
   "source": [
    "string = \"<head><title> My amazing webpage </title></head><body> Welcome to my webpage! </body>\"\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = \"<[A-z]{0,4}>?\"# write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, string, re.M)  # re.M enables tha tpettern to be searched in multiple lines\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "if (result != None) and (len(result.group()) <= 6):\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
